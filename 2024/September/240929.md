# BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation

읽은 이유: multimodal dialogue를 하게 되면 이런 내용 참고해야 할듯.. image generation 할 때 진짜 consistency가 없으면 문제인듯.

https://arxiv.org/pdf/2408.05926

image history 사용
![image](https://github.com/user-attachments/assets/39ba5c94-2053-4278-880b-701d0797510e)

- 기존 문제
  - image grounding 잘 안됨, image response가 inconsistent
  - 기존엔 txt description으로 이미지를 생성해왔어서 이미지 history 고려 안함
- Contribution
  - visual feature를 language model과 cross-attention을 통해 integrate
  - citation module을 이용해서 image history와 image response를 연결

### Related work
- Multimodal dialogue dataset
  - MMChat, TicTalk: 중국어
  - MMDD, DialogCC: 알고리즘으로 synthesize
  - ImageChat, PhotoChat, MMDialog: 이거 중심
    - ImageChat: 하나의 이미지 중심
    - PhotoChat: social media로 모음, 적은 양
    - MMDialog: social media로 모음, 가장 realistic 
- Divter: MDRG 에서 high resolution images를 만든 좋은 논문
- Text inversion, model 안바꾸고 identifier로 바꿈
  - Dreambooth, Custom Diffusion, BLIP-Diffusion

### Method

![image](https://github.com/user-attachments/assets/3af48305-8380-4b74-b229-9172b53264d6)

- Flamingo
- citation-augmented descriptions
![image](https://github.com/user-attachments/assets/2cd296df-ff0d-4cbf-bc42-104600b2b945)
